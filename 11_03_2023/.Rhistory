getwd()
gc()
library(haven)
data <- read_dta("childrenfinal.dta")
getwd()
##########PRAT(a)#####################################################################
library(haven)
data <- read_dta("childrenfinal.dta")
library(haven)
data <- read_dta("childrenfinal.dta")
library(haven)
data <- read_dta("childrenfinal.dta")
data <- read_dta("childrenfinal")
data <- read_dta("childrenfinal")
data <- read_dta("childrenfinal.dta")
data <- read_dta(childrenfinal.dta)
getwd
getwd()
data <- read_dta("childrenfinal.dta")
data <- read_dta("childrenfinal.DTA")
data <- read_dta("childrenfinal.dta")
data <- read_dta("childrenfinal.dta")
data <- read("childrenfinal.dta")
data <- read_dta("childrenfinal")
create_random_sample <- function(n, p) {
sample(1:n, size = ceiling(n * p), replace = FALSE)
}
random_num= create_random_sample(100,0.05)
random_num
# Define the function to create train and test datasets
create_train_test_datasets <- function(dataset, indices) {
# Extract train set using specified indices
train_set <- dataset[indices]
# Extract test set using remaining indices
test_set <- dataset[-indices]
# Return train and test sets as a list
return(list(train_set = train_set, test_set = test_set))
}
# Define the normalize_datasets function
normalize_datasets <- function(train_set, test_set) {
# Compute mean and standard deviation of the train set
train_mean <- mean(train_set)
train_sd <- sd(train_set)
test_mean <- mean(test_set)
test_sd <- sd(test_set)
# Apply normalization to train set
normalized_train_set <- scale(train_set, center = train_mean, scale = train_sd)
# Apply the same transformation to the test set
normalized_test_set <- scale(test_set, center = test_mean, scale = test_sd)
# Return both normalized datasets
return(list(normalized_train_set = normalized_train_set, normalized_test_set = normalized_test_set))
}
source("create_train_test_datasets.R")
source("create_random_sample.R")
source("normalize_datasets.R")
# Access the waiting column of the faithful dataset
data <- faithful$waiting
n <- length(data)
random_num<-create_random_sample(n,0.5)
# Create train and test datasets using the function
result <- create_train_test_datasets(data, random_num)
# Access train and test sets
train_set <- result$train_set
test_set <- result$test_set
# Normalize the datasets
normalized_data <- normalize_datasets(train_set, test_set)
# Access the normalized train and test sets
normalized_train_set <- normalized_data$normalized_train_set
normalized_test_set <- normalized_data$normalized_test_set
# Print the normalized datasets
print("Normalized Train Set:")
hist(normalized_train_set)
print("Normalized Test Set:")
hist(normalized_test_set)
# Print the normalized datasets
print("Normalized Train Set:")
hist(normalized_train_set,main = "Histogram of Train data set", xlab = "Normalized train data point", ylab = "Frequency")
print("Normalized Test Set:")
hist(normalized_test_set,main = "Histogram of Test data set", xlab = "Normalized test data point", ylab = "Frequency")
# Function to create a random sample
# Arguments:
#   n: The total number of elements in the sample population
#   p: The proportion of elements to sample from the population
# Returns:
#   A random sample of indices from the population
create_random_sample <- function(n, p) {
# Use the sample() function to generate a random sample of indices
# from 1 to n, with replacement set to FALSE (no duplicates)
# The size of the sample is calculated as the ceiling of (n * p),
# ensuring at least one element is sampled if p is not a whole number
sample(1:n, size = ceiling(n * p), replace = FALSE)
}
# Call the function to create a random sample
# Here, it generates a random sample of 5% of the indices from
# a population of 100 elements
random_num = create_random_sample(100, 0.05)
# Print the random sample
random_num
# Define the normalize_datasets function
normalize_datasets <- function(train_set, test_set) {
# Compute mean and standard deviation of the train set
train_mean <- mean(train_set)
train_sd <- sd(train_set)
test_mean <- mean(test_set)
test_sd <- sd(test_set)
# Apply normalization to train set
normalized_train_set <- scale(train_set, center = train_mean, scale = train_sd)
# Apply the same transformation to the test set
normalized_test_set <- scale(test_set, center = test_mean, scale = test_sd)
# Return both normalized datasets
return(list(normalized_train_set = normalized_train_set, normalized_test_set = normalized_test_set))
}
source("create_train_test_datasets.R")
source("create_random_sample.R")
source("normalize_datasets.R")
# Access the waiting column of the faithful dataset
data <- faithful$waiting
n <- length(data)
random_num<-create_random_sample(n,0.5)
# Create train and test datasets using the function
result <- create_train_test_datasets(data, random_num)
# Access train and test sets
train_set <- result$train_set
test_set <- result$test_set
# Normalize the datasets
normalized_data <- normalize_datasets(train_set, test_set)
# Access the normalized train and test sets
normalized_train_set <- normalized_data$normalized_train_set
normalized_test_set <- normalized_data$normalized_test_set
# Print the normalized datasets
print("Normalized Train Set:")
hist(normalized_train_set,main = "Histogram of Train data set", xlab = "Normalized train data point", ylab = "Frequency")
print("Normalized Test Set:")
hist(normalized_test_set,main = "Histogram of Test data set", xlab = "Normalized test data point", ylab = "Frequency")
# This function creates train and test datasets from a given dataset based on specified indices.
# Arguments:
#   dataset: The original dataset from which to create train and test sets.
#   indices: A vector of indices specifying which rows of the dataset belong to the train set.
# Returns:
#   A list containing the train and test datasets.
create_train_test_datasets <- function(dataset, indices) {
# Extract the train set using the specified indices
train_set <- dataset[indices]
# Extract the test set using the remaining indices
test_set <- dataset[-indices]
# Return the train and test sets as a list
return(list(train_set = train_set, test_set = test_set))
}
# Function to create train and test datasets from a given dataset
# Arguments:
#   dataset: The dataset from which to create train and test sets
#   indices: The indices specifying which rows of the dataset belong to the train set
# Returns:
#   A list containing the train and test datasets
create_train_test_datasets <- function(dataset, indices) {
# Extract the train set using the specified indices
train_set <- dataset[indices]
# Extract the test set using the remaining indices
test_set <- dataset[-indices]
# Return the train and test sets as a list
return(list(train_set = train_set, test_set = test_set))
}
# Function to create a random sample
# Arguments:
#   n: The total number of elements in the sample population
#   p: The proportion of elements to sample from the population
# Returns:
#   A random sample of indices from the population
create_random_sample <- function(n, p) {
# Use the sample() function to generate a random sample of indices
# from 1 to n, with replacement set to FALSE (no duplicates)
# The size of the sample is calculated as the ceiling of (n * p),
# ensuring at least one element is sampled if p is not a whole number
sample(1:n, size = ceiling(n * p), replace = FALSE)
}
# Call the function to create a random sample
# Here, it generates a random sample of 5% of the indices from
# a population of 100 elements
random_num = create_random_sample(100, 0.05)
# Print the random sample
random_num
# Load the custom functions for creating train and test datasets, generating random samples, and normalizing datasets
source("create_train_test_datasets.R")
source("create_random_sample.R")
source("normalize_datasets.R")
# Access the waiting column of the faithful dataset
data <- faithful$waiting
n <- length(data)
# Generate a random sample to split the dataset into train and test sets
random_num <- create_random_sample(n, 0.5)
# Create train and test datasets using the function
result <- create_train_test_datasets(data, random_num)
# Access train and test sets
train_set <- result$train_set
test_set <- result$test_set
# Normalize the datasets
normalized_data <- normalize_datasets(train_set, test_set)
# Access the normalized train and test sets
normalized_train_set <- normalized_data$normalized_train_set
normalized_test_set <- normalized_data$normalized_test_set
# Print the normalized datasets along with histograms
print("Normalized Train Set:")
hist(normalized_train_set, main = "Histogram of Train data set", xlab = "Normalized train data point", ylab = "Frequency")
print("Normalized Test Set:")
hist(normalized_test_set, main = "Histogram of Test data set", xlab = "Normalized test data point", ylab = "Frequency")
# Load necessary packages
library(readr)
# Load necessary packages
library(readr)
library(lubridate)
library(dplyr)
# Hill estimator function
Hill_estimator <- function(data, k) {
data <- as.numeric(data)
sorted_data <- sort(data, decreasing = TRUE)
top_k <- sorted_data[1:(k - 1)]
last_k <- sorted_data[k]
avg <- sum(log(top_k)) / k  - log(last_k)
return(avg)
}
# Function to plot multiple Hill estimates
hill_estimator_plot_multiple <- function(ks, cauchy_samples, dataset_name) {
# Initialize list to store Hill estimates for each column
hill_estimates <- vector("list", 5)
# Calculate Hill estimates for each column
for (col in 1:5) {
hill_estimates[[col]] <- sapply(ks, function(k) Hill_estimator(cauchy_samples[, col], k))
}
# Convert list to data frame
df <- data.frame(k = rep(ks, times = 5),
Hill_Estimate = unlist(hill_estimates),
Column = factor(rep(1:5, each = length(ks))))
# Plot line graph
library(ggplot2)
ggplot(df, aes(x = k, y = Hill_Estimate, color = Column)) +
geom_line() +
labs(x = "k", y = "Hill Estimate",
title = paste("Hill Estimates for fives Columns of", dataset_name, "and different Values of k")) +
scale_color_discrete(name = "Column")
}
# Set the seed for reproducibility
set.seed(123)
# Number of samples
num_samples <- 100
# Sample size
sample_size <- 1000
# Simulate data
cauchy_samples <- matrix(rcauchy(num_samples * sample_size), nrow = sample_size)
frechet_samples <- matrix(rf(num_samples * sample_size, df1 = 1, df2 = 1, ncp = 0), nrow = sample_size)
student_samples <- matrix(rt(num_samples * sample_size, df = 3), nrow = sample_size)
kc <- seq(10, 450)
kf <- seq(10, 850)
ks <- seq(10, 400)
# Example usage
hill_estimator_plot_multiple(kc, cauchy_samples, "Cauchy samples")
hill_estimator_plot_multiple(kf, frechet_samples, "Frechet samples")
hill_estimator_plot_multiple(ks, student_samples, "Student samples")
# Range for each ks value
kc_range <- seq(100, 200)
kf_range <- seq(200, 370)
ks_range <- seq(100, 250)
# Function to calculate Hill estimates matrix
Hill_estimates_matrix <- function(ks, data) {
hill_estimates <- matrix(NA, nrow = ncol(data), ncol = length(ks))
for (j in seq_along(ks)) {
for (i in 1:ncol(data)) {
hill_estimates[i, j] <- Hill_estimator(data[, i], k = ks[j])
}
}
return(t(hill_estimates))
}
# Function to plot histogram of Hill estimates
Hill_estimates_histogram <- function(data, kc, dataset_name) {
Cauchy_matrix <- Hill_estimates_matrix(kc, data)
mean_over_k <- list()
for (i in 1:ncol(Cauchy_matrix)) {
mean_over_k[[i]] <- mean(Cauchy_matrix[, i])
}
unlisted_mean <- unlist(mean_over_k)
hist(unlisted_mean, breaks = 10, main = paste("Histogram of Hill Estimates for", dataset_name), xlab = "Average values of Hill Estimator over k")
}
# Plot histograms
Hill_estimates_histogram(cauchy_samples, kc_range, "Cauchy Samples")
Hill_estimates_histogram(frechet_samples, kf_range, "Frechet Samples")
Hill_estimates_histogram(student_samples, ks_range, "Student Samples")
###################################TASK_2###############################
density_function <- function(x, gamma) {
if (1 + gamma * x <= 0) {
return(0)  # Return zero density outside of the domain
}
return(exp(-((1 + gamma * x) ^ (-1 / gamma)))*((1+gamma*x)^((-1-gamma)/(gamma))))
}
data <- read.csv("39001_gdf.csv")
